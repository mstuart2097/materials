---
title: "Stat 585 - Reading data from files"
author: "Heike Hofmann"
ratio: 16x10
output:
  rmdshower::shower_presentation:
    self_contained: false
    katex: true
    theme: ribbon
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Reading Data

## 95 printable characters {.black}

<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/42/ASCII_full.svg/217px-ASCII_full.svg.png" class="cover">

## ASCII

- short for American  Standard  Code for  Information  Interchange (1960, Bell Data)
- developed from telegraph code (such as Morse code)
- enables text representation on computers, screens and  communication devices
- uses 7-bit binary integers
- encodes 128 specified characters, numbers 0-9, letters a-z, A-Z, some basic punctuation, and (some now obsolete) control codes

## ASCII reference card

<img src="https://upload.wikimedia.org/wikipedia/commons/8/82/US-ASCII_code_chart.png" alt="ASCII image" width=650>


## ASCII

- printable characters: 100 0001=A, 100 0010=B, 110 0001=a, 110 0010=b, ...
- first 32 chars are for control, e.g. 000 1000=BS=backspace, 111 1111=DEL=delete, 
- horizontal tab (000 1001=HT \t), line feed (000 1010=LF \n) and carriage return (000 1101=CR \r) are also control codes
- Advantage of ASCII: human readable, less prone to error/can be humanly checked

[http://en.wikipedia.org/wiki/Ascii]



## ASCII and R

- base R supports reading ASCII files, e.g. ```read.table(), read.csv(), read.delim()``` reads data from ASCII files with specified delimiters 
- ```write.table()``` writes ASCII files
- the ```readr``` package provides similar functionality: ```read_csv, read_tsv, read_delim```
- ```readr``` functions are faster than base R functions, if the whole file is being read at once

## Binary file formats

- No restriction in terms on content, streams of bytes
- Advantage: Generally much smaller files, and with compression even smaller, e.g. `nasadata.csv` is 3.7Mb, `nasadata.rds` is 288kb
- Disadvantage: Can be machine-dependent

## Binary files and R

- ```saveRDS()``` saves a single R object in binary format, use extension `.rds`
- ```readRDS()``` reads R binary file
- ```save()``` saves all objects in a binary file (and keeps their names), use extension `.rda` 
- ```load()``` retrieves these objects (using the same names)

## Example

```{r}
system.time(d1 <- read.csv("../data/nasadata.csv"))
dim(d1)
d1[1,]
```

## Example

```{r}
system.time(d2 <- readRDS("../data/nasadata.rds"))
dim(d2)
d2[1,]
```

## Awkward text formats and R

The National Climate Data Center at NOAA publishes information on temperature and precipation across a network of stations in the US.

The Data can be accessed through ftp at ftp://ftp.ncdc.noaa.gov/pub/data/ushcn/v2.5, a code book with a description of the data structure is available at
ftp://ftp.ncdc.noaa.gov/pub/data/ushcn/v2.5/readme.txt

```{r}
temp.all<-readLines("../data/USH00132999.raw.tmax", n = 5)
temp.all
```

## From the code book

```
2.2.1 DATA FORMAT

          Variable          Columns      Type
          --------          -------      ----

          ID                 1-11        Integer
          YEAR              13-16        Integer
          VALUE1            17-22        Integer
          DMFLAG1           23-23        Character
          QCFLAG1           24-24        Character
          DSFLAG1           25-25        Character
            .                 .             .
            .                 .             .
            .                 .             .
          VALUE12          116-121       Integer
          DMFLAG12         122-122       Character
          QCFLAG12         123-123       Character
          DSFLAG12         124-124       Character
```

## Fixed width format

- Fixed formats can be read with ```read.fwf()``` or ```readr::read_fwf()```
- Need to specify column positions: pretty painful to specify

```{r message=FALSE, warning = FALSE}
library(tidyverse)
temps <- read_fwf("../data/USH00132999.raw.tmax",
  col_positions = fwf_positions(
    start=c( 1,13, rep(16+9*0:11, each=4) + c(1,7,8,9)), 
    end  =c(11,16, rep(16+9*0:11, each=4) + c(6,7,8,9))))
names(temps) <- c("Station", "Year", 
  paste0(rep(c("Value","DMflag", "QCflag", "DSflag"), 12), 
         rep(1:12, each=4)))
```

## 

```{r warning = FALSE, message = FALSE, fig.height =4}
FortDodge <- temps %>% 
  gather(key="Month", value="Temp_Max", starts_with("Value"))
FortDodge$Month <- as.numeric(gsub("Value", "", FortDodge$Month))
FortDodge$Temp_Max <- replace(FortDodge$Temp_Max, 
                              FortDodge$Temp_Max == -9999, NA)

FortDodge %>% ggplot(aes(x = Year, Temp_Max/100)) + 
  geom_point() + facet_wrap(~Month, nrow=2) 
```

## Your turn (10 min)

The file `ushcn-v2.5-stations.txt` contains information on all weather stations in the USHCN network. This file is also in fixed width format.
**Read the file into R and plot latitude versus longitude.**

```
	----------------------------------------
	Variable             Columns    Type
	----------------------------------------
	COUNTRY CODE             1-2    Character
	NETWORK CODE               3    Character
	ID PLACEHOLDERS ("00")   4-5    Character
	COOP ID                 6-11    Character
	LATITUDE               13-20    Real
	LONGITUDE              22-30    Real
	ELEVATION              33-37    Real
	STATE                  39-40    Character
	NAME                   42-71    Character
	COMPONENT 1 (COOP ID)  73-78    Character
	COMPONENT 2 (COOP ID)  80-85    Character
	COMPONENT 3 (COOP ID)  87-92    Character
	UTC OFFSET             94-95    Integer
	-----------------------------------------
```

## HTML FILES 

- A lot of data is available online in the form of html tables
- Extracting the data requires recognizing the html table format, and stripping off the html
- Packages such as `xml`, `rvest`, ... helps with this

## HTML FILES 

Pulling election results off the web...

```{r warnings=FALSE, message=FALSE}
library(rvest)
url <- "http://www.nytimes.com/elections/results/iowa"
doc <- read_html(url)
tables <- html_table(doc, fill=TRUE)
head(tables[[2]])
```

## Other binary formats and R

- Packages ```foreign``` or ```haven```: Data export/import for other (statistical) software: Stata, Epi, Octave, SPSS, Systat, SAS
- Package ```readxl``` import/export with Excel spreadsheets
e.g. web index data at http://www.visualizing.org/datasets/web-index-2013


```{r, eval = FALSE}
library(foreign)
knights <- read.spss("../data/knightfoundation2008sotcdata.por")
str(knights)
```

## JSON

- JSON is short for JavaScript  Object Notation (http://json.org/) 
- it is a lightweight data interchange format, becoming popular
- Human readable and writable
- Utilized by many web APIs, e.g. tumblr, twitter, ... 
- ... and also the Census Bureau!

e.g. result from get query in JSON format:

```
[["P0010001","NAME","state"],
 ["710231","Alaska","02"],
 ["4779736","Alabama","01"],
 ["2915918","Arkansas","05"],
 ["6392017","Arizona","04"],
 ["37253956","California","06"]]
```

i.e. vector of vector format - focus is on individual rows in a data set, whereas R puts emphasis on individual columns (data set is list of vectors).


## Example: Census Bureau API


```{r, eval = TRUE, message = FALSE}
library(devtools)
if (!require(cbapi)) {
  install_github("heike/cbapi") # run this the first time 
  library(cbapi)
}
setkey("7f784587c3918611ad6ca67188d9b269b3558dd4") # my key - if you want to use this, get your own :)
# population based on 2010 Census:
popstate <- read.census(sprintf("http://api.census.gov/data/2010/sf1?key=%s&get=P0010001,NAME&for=state:*", getkey()))
head(popstate)
```

## Why do we need to access all these formats? 

- To solve a problem, may need to collate data from multiple sources
- Rearranging and merging data from different sources helps to pull together the data necessary to solve the problem

## Reading and blog

Watch the talk Prof Donald Knuth gave at the useR!2016. Based on that, answer the following questions:

- What role does literate programming play in your life so far?
- Where do you see potential in applying literate programming in your workflow?

Make a blog entry by 10 pm <s>Tuesday, Jan 24</s> Wednesday, Jan 25.

## Accessing the blog

1. Navigate to the repo https://github.com/Stat585-at-ISU/blog
2. Fork this repo.
2. In the folder `01` is the file LastnameFirstname.Rmd
3. **Copy** the file LastnameFirstname.Rmd (Do NOT change the original file).
4. Rename the copy with your last and first name.
5. Follow the instructions within the file. 
